# 训练问题分析与修复

## 当前问题

从训练日志看到的问题：

```
Train Loss: 0.0001  (太低了！)
Val Loss: 0.0001    (也太低了！)
Val Metrics: MSE=76, RMSE=8.7 (异常大)
只训练了5个epoch就停了
```

## 问题诊断

### 1. Loss过低的根本原因

**负采样不足**:
- `neg_ratio: 1` 表示每个正样本只有1个负样本
- 模型学得太容易，很快就过拟合
- 损失迅速降到接近0

**Logit Scale过大**:
- 初始值 `10.0` 太大
- 导致相似度分数被放大太多
- 模型过度自信，loss快速收敛

### 2. 训练轮数太少

只有5个epoch，模型还没充分学习就已经收敛了。

## 修复方案

### 修改1: 增加负采样

```yaml
data:
  neg_ratio: 5  # 从1改为5
```

**效果**: 每个正样本有5个负样本，学习更困难，loss不会过早降到0

### 修改2: 降低Logit Scale

```yaml
model:
  logit_scale: 1.0  # 从10.0改为1.0
```

**效果**: 
- 更保守的初始缩放
- 模型可以学习逐步增大
- 避免过度自信

### 修改3: 增加训练轮数

```yaml
training:
  num_epochs: 20  # 从5改为20
```

**效果**: 给模型更多时间学习，不会过早停止

## 预期改善

修改后重新训练，应该看到：

```
Epoch 1:  Train Loss: 0.65, Val Loss: 0.68  (正常范围)
Epoch 5:  Train Loss: 0.45, Val Loss: 0.52  (逐渐下降)
Epoch 10: Train Loss: 0.35, Val Loss: 0.42  (持续改善)
Epoch 15: Train Loss: 0.28, Val Loss: 0.36  (收敛)
Epoch 20: Train Loss: 0.25, Val Loss: 0.33  (最终)
```

### 正常的学习曲线

```
损失轨迹：
0.70 -> 0.65 -> 0.55 -> 0.45 -> 0.38 -> 0.32 -> 0.28 -> 0.25
         ↑       ↑       ↑       ↑       ↑       ↑       ↑
       Epoch1  Epoch3  Epoch5  Epoch8  Epoch12 Epoch16 Epoch20
```

## 为什么这样修改有效？

### 1. 负采样比例的作用

**neg_ratio=1 (太容易)**:
- 每1个正样本 vs 1个负样本
- 学习任务太简单，模型快速过拟合
- Loss迅速降到接近0

**neg_ratio=5 (更合理)**:
- 每1个正样本 vs 5个负样本
- 增加了学习难度
- 模型需要学习更好的表示才能区分
- Loss不会过早收敛

### 2. Logit Scale的平衡

**logit_scale=10.0 (太大)**:
- 相似度分数 [-1, 1] → [-10, 10]
- 范围太大，模型过度自信
- sigmoid压缩后差异变小
- 反而降低了学习效率

**logit_scale=1.0 (更合适)**:
- 相似度分数 [-1, 1] → [-1, 1]
- 保持原始范围，避免极端值
- 模型可以逐步学习更大的scale
- 梯度传播更稳定

### 3. 训练轮数的影响

**5 epochs**:
- 模型还没完全学习就停止了
- 可能还在"学习阶段"，尚未达到最佳性能

**20 epochs**:
- 给模型足够时间探索
- 可以看到完整的收敛曲线
- 找到最佳模型状态

## 关于验证指标异常

你看到的这些指标：

```
Val Metrics: MSE=76, RMSE=8.7
```

**这是正常的！** 原因：

1. **验证集只有正样本**（neg_ratio=0）
2. **指标计算的是 similarity_score vs label**
3. **similarity_score 是点积（范围 ~[-1, 1]），不是1**
4. **所以 MSE = (similarity - 1)²，当然会比较大**

但这些指标在验证集上**不重要**，重要的是：
- **损失函数是否下降** ✅
- **模型是否在学习** ✅
- **训练/验证损失是否收敛** ✅

## 重新训练建议

```bash
conda activate pytorch
python scripts/training/train_two_tower.py
```

预期看到：
- 训练损失从 0.6-0.7 开始
- 逐步下降到 0.2-0.3
- 验证损失同步下降
- 不会像之前那样卡在某个值

## 监控要点

关注这些指标：

1. **Train/Val Loss**: 应该都下降，不要过早接近0
2. **Loss gap**: Train loss 应该始终略低于 Val loss
3. **收敛趋势**: 应该是平滑下降曲线，不是突然跳到0
4. **验证指标**: 主要看RMSE是否稳定在合理范围（0.1-0.5）

## 总结

已做的修改：
- ✅ `neg_ratio: 1 → 5` (增加负样本)
- ✅ `logit_scale: 10.0 → 1.0` (降低初始缩放)
- ✅ `num_epochs: 5 → 20` (增加训练轮数)

现在可以重新训练了！应该会看到更合理的学习曲线。

